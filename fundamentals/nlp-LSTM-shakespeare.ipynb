{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"nlp-LSTM-shakespeare.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNDoA4UV6GbwImnGyemd2Ye"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"FFgB9KBKj_CM","colab_type":"text"},"source":["# import libraries"]},{"cell_type":"code","metadata":{"id":"rtWoMYtukO4q","colab_type":"code","outputId":"586c3136-129f-458c-bf56-2524d0a7cdea","executionInfo":{"status":"ok","timestamp":1587272536021,"user_tz":240,"elapsed":1934,"user":{"displayName":"Enzo Vernon","photoUrl":"","userId":"09908679712030615005"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import tensorflow as tf\n","from tensorflow import keras\n","print(tf.__version__)\n","\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","import os\n","import numpy as np\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg \n","\n","import tensorflow.keras.utils as ku\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2.2.0-rc3\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SYNg6HGCuyb2","colab_type":"text"},"source":["# define helper functions"]},{"cell_type":"code","metadata":{"id":"AE5DBBdsu0eX","colab_type":"code","colab":{}},"source":["def plot_graphs(history, metric):\n","  plt.plot(history.history[metric])\n","  plt.plot(history.history['val_'+metric])\n","  plt.xlabel('time')\n","  plt.ylabel(metric)\n","  plt.grid(True)\n","  print('blue: {}'.format(metric))\n","  print('orange: {}'.format('val_'+metric))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uW_Nxoikk7gY","colab_type":"text"},"source":["# get dataset"]},{"cell_type":"code","metadata":{"id":"J1CbeCQik_ZC","colab_type":"code","outputId":"ab93407e-457d-4aa5-b551-3fc23ef86068","executionInfo":{"status":"ok","timestamp":1587272536813,"user_tz":240,"elapsed":2691,"user":{"displayName":"Enzo Vernon","photoUrl":"","userId":"09908679712030615005"}},"colab":{"base_uri":"https://localhost:8080/","height":224}},"source":["!wget --no-check-certificate \\\n","    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sonnets.txt \\\n","    -O /tmp/sonnets.txt"],"execution_count":0,"outputs":[{"output_type":"stream","text":["--2020-04-19 05:02:16--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sonnets.txt\n","Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.195.128, 2607:f8b0:400e:c04::80\n","Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.195.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 93578 (91K) [text/plain]\n","Saving to: ‘/tmp/sonnets.txt’\n","\n","\r/tmp/sonnets.txt      0%[                    ]       0  --.-KB/s               \r/tmp/sonnets.txt    100%[===================>]  91.38K  --.-KB/s    in 0.001s  \n","\n","2020-04-19 05:02:16 (117 MB/s) - ‘/tmp/sonnets.txt’ saved [93578/93578]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cVYv5Vl9lBc4","colab_type":"code","colab":{}},"source":["# open & read data\n","data = open('/tmp/sonnets.txt').read()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8fKawCLllW0Y","colab_type":"text"},"source":["# preprocess\n","\n","**tokenize sentences**\n","\n","tokenize means to split corpus dataset into encoded words (words in numeric representation)\n"]},{"cell_type":"code","metadata":{"id":"XjgyNJeZlt8H","colab_type":"code","colab":{}},"source":["# transform your corpus into all lowercase\n","corpus = data.lower()\n","# split the corpus into sentences by new line \n","corpus = corpus.split('\\n')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"p4wV_7RfmymJ","colab_type":"code","colab":{}},"source":["# instantiate tokenizer to generate word index dictionary\n","tokenizer = Tokenizer()\n","\n","# .fit_on_texts() to tokenize training sentences\n","tokenizer.fit_on_texts(corpus)\n","\n","# get word_index dictionary= word:index\n","word_index = tokenizer.word_index\n","print('word_index: \\n{}'.format(word_index))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JIgCq_bEnDNM","colab_type":"code","outputId":"bc799908-0ff5-42ed-c99f-0749a09fb221","executionInfo":{"status":"ok","timestamp":1587272537028,"user_tz":240,"elapsed":2825,"user":{"displayName":"Enzo Vernon","photoUrl":"","userId":"09908679712030615005"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# get vocab_size\n","vocab_size = len(tokenizer.word_index) + 1\n","print('vocab_size: \\n{}'.format(vocab_size))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["vocab_size: \n","3211\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AZYS7TaUnpv-","colab_type":"code","colab":{}},"source":["# create input sequences using training word_index\n","input_sequences = []\n","for line in corpus:\n","  # texts_to_sequences() transforms list of sentences into lists of numeric representation\n","    # uses training word_index\n","  token_list = tokenizer.texts_to_sequences([line])[0]\n","  for i in range(1, len(token_list)):\n","    n_gram_sequences = token_list[:i+1]\n","    input_sequences.append(n_gram_sequences)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MzIYCpHpoQgA","colab_type":"code","colab":{}},"source":["# pad_sequences() transforms sentence/sequence into a uniform input_shape \n","  # padding= 'post' because default padding adds 0's to beginning \n","  # maxlen= max length of sequence\n","max_sequences_len = max([len(x) for x in input_sequences])\n","padded = pad_sequences(input_sequences, maxlen=max_sequences_len)\n","\n","# convert training sequences \n","padded = np.array(padded)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i2ISP38zrQiC","colab_type":"code","colab":{}},"source":["# create predictors and labels\n","train_padded, labels = padded[:, :-1], padded[:, -1]\n","\n","# one-hot encode\n","labels = ku.to_categorical(labels, num_classes=vocab_size)\n","\n","print('train_padded: \\n{}'.format(train_padded))\n","print('labels: \\n{}'.format(labels))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RcXn9vLfvlMD","colab_type":"text"},"source":["# define hyperparameters"]},{"cell_type":"code","metadata":{"id":"cOPkrWSgvm98","colab_type":"code","colab":{}},"source":["embedding_dimensions = 100\n","max_length = max_sequences_len - 1\n","num_epochs = 100"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OoptSbn3rw2Q","colab_type":"text"},"source":["# define the model\n","\n","**embedding process**\n","\n","words are mapped in higher dimensional space, and semantics of the words are then learned when those words are labeled with similar meaning. \n","\n","*movie review examples:*\n","- movie reviews with positive sentiment had the dimensionality of their words ended up 'pointing' in a particular direction\n","\n","- movie reviews with negative sentiment 'pointed' in a different direction\n","\n","after model training, words in future sentences could have their direction established as positive or negative (inferred sentiment)"]},{"cell_type":"code","metadata":{"id":"ckT12ogpsDcN","colab_type":"code","outputId":"7f9778df-56db-4b6d-ff92-89bed0a59189","executionInfo":{"status":"ok","timestamp":1587272545234,"user_tz":240,"elapsed":10879,"user":{"displayName":"Enzo Vernon","photoUrl":"","userId":"09908679712030615005"}},"colab":{"base_uri":"https://localhost:8080/","height":357}},"source":["model = keras.Sequential([\n","  # input_layer\n","  # over time, words cluster together due to the training labels (word meaning)\n","    # embedding= words found together are given similar vectors (shape & direction)\n","  # embedding output_shape=(sentence_length, embedding_size)\n","    # embedding_dimension=num_neurons\n","  keras.layers.Embedding(vocab_size, embedding_dimensions, input_length=max_length),\n","  # bidirectional= flowing 'cell state' goes both directions\n","  # return_sequences= when stacking LSTM layers, feeding an LSTM into another\n","    # requires the output of LSTM(current) to match the desired input of LSTM(next)\n","  keras.layers.Bidirectional(keras.layers.LSTM(units=150, return_sequences=True)),\n","  # randomly deactivate % of neurons in hidden layer\n","  keras.layers.Dropout(0.2),\n","  keras.layers.Bidirectional(keras.layers.LSTM(units=100)),\n","  # L2 regularization= give features different weights of importance \n","  # relu= return x if x > 0, else return 0\n","  keras.layers.Dense(units=vocab_size/2, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)),\n","  # output_layer\n","  # softmax= organize prediction neurons into valid distribution of 100% \n","  keras.layers.Dense(units=vocab_size, activation='softmax')\n","])\n","\n","model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, 10, 100)           321100    \n","_________________________________________________________________\n","bidirectional (Bidirectional (None, 10, 300)           301200    \n","_________________________________________________________________\n","dropout (Dropout)            (None, 10, 300)           0         \n","_________________________________________________________________\n","bidirectional_1 (Bidirection (None, 200)               320800    \n","_________________________________________________________________\n","dense (Dense)                (None, 1605)              322605    \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 3211)              5156866   \n","=================================================================\n","Total params: 6,422,571\n","Trainable params: 6,422,571\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yxech8JQr5CW","colab_type":"text"},"source":["# compile the model\n","\n","build the model by compiling it with a loss, optimizer, and objective metrics\n","- loss= prediction accuracy\n","- the optimizer uses the loss to adjust & improve prediction performance per epoch\n","- metrics= target"]},{"cell_type":"code","metadata":{"id":"xGnpfpk4sC7r","colab_type":"code","colab":{}},"source":["model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EbKNF1TOynE4","colab_type":"text"},"source":["# define callbacks"]},{"cell_type":"code","metadata":{"id":"fPzlJd07yoXH","colab_type":"code","colab":{}},"source":["# enable early stopping \n","class myCallback(keras.callbacks.Callback):\n","  def on_epoch_end(self, epoch, logs={}):\n","    if logs.get('acc') > .97:\n","      self.model.stop_training = True\n","\n","callbacks = myCallback()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3ZfrKOvAyNZV","colab_type":"text"},"source":["# train the model\n","\n","fit the model to trian & learn the optimal weights/relationships"]},{"cell_type":"code","metadata":{"id":"Lj0dwnFRyTqu","colab_type":"code","colab":{}},"source":["# assign train model to a history var for performance querying\n","history = model.fit(train_padded, labels, epochs=num_epochs, callbacks=[callbacks], verbose=1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0UmkfNNdsEjD","colab_type":"text"},"source":["# visualize performance"]},{"cell_type":"code","metadata":{"id":"GPuXns5JsJXw","colab_type":"code","colab":{}},"source":["plt.figure(figsize=(10,6))\n","plot_graphs(history, 'acc')\n","plot_graphs(history, 'loss')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"73kraQ6BsLkU","colab_type":"text"},"source":["# test the model"]},{"cell_type":"code","metadata":{"id":"QbdsXh2osOiu","colab_type":"code","colab":{}},"source":["seed_text = \"Help me Obi Wan Kenobi, you're my only hope\"\n","next_words = 100\n","\n","for _ in range(next_words):\n","  # preprocess with tokenizer\n","\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n","\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n","\t# get label/class probabilities\n","  predicted = model.predict_classes(token_list, verbose=0)\n","\toutput_word = \"\"\n","  # map word to label\n","\tfor word, index in tokenizer.word_index.items():\n","\t\tif index == predicted:\n","\t\t\toutput_word = word\n","\t\t\tbreak\n","  # generate text from rnn predictions\n","\tseed_text += \" \" + output_word\n","print(seed_text)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ijg5ZaWpsXTI","colab_type":"text"},"source":["# clean up\n","\n","terminate the kernel to free up memory "]},{"cell_type":"code","metadata":{"id":"9sRSwi_Isn9d","colab_type":"code","colab":{}},"source":["import os, signal\n","\n","# os.kill(os.getpid(), signal.SIGKILL)"],"execution_count":0,"outputs":[]}]}