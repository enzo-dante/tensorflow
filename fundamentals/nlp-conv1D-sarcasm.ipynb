{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"nlp-conv1D-sarcasm.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNKVxSQDvYMvajhHArG9fEd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"smfUMXg2wFT9","colab_type":"text"},"source":["# import libraries"]},{"cell_type":"code","metadata":{"id":"jD31-bIowNTE","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","from tensorflow import keras\n","print(tf.__version__)\n","\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","import json\n","import numpy as np\n","import matplotlib.pyplot as plt\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fatho-rxxCRC","colab_type":"text"},"source":["# define helper functions"]},{"cell_type":"code","metadata":{"id":"5HCT_3Q9xDup","colab_type":"code","colab":{}},"source":["def plot_graphs(history, metric):\n","  plt.plot(history.history[metric])\n","  plt.plot(history.history['val_'+metric])\n","  plt.xlabel('time')\n","  plt.ylabel(metric)\n","  plt.grid(True)\n","  print('blue: {}'.format(metric))\n","  print('orange: {}'.format('val_'+metric))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kW6nGezBw_Tn","colab_type":"text"},"source":["# define hyperparameters"]},{"cell_type":"code","metadata":{"id":"b1_mjFElxXR0","colab_type":"code","colab":{}},"source":["vocab_size = 1000 # number of word tokens to generate ordered by frequenc\n","max_length = 120 # max length of sentence \n","trunc_type = 'post' # if sentence exceeds max_length, cut from end\n","pad_type = 'post' # if sentence is short, pad with 0's on end\n","oov_token = '<OOV>' # token substitute for words not found in word_index\n","train_size = 20000 # where to split training & testing datasets in main dataset\n","num_epochs = 50"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T1tvFsrVyT2l","colab_type":"text"},"source":["as an nlp neural network trains, it learns vectors and associates vectors with labels to come up with an EMBEDDING\n","- embedding= vector for each word with associated label\n","- embedding layer returns 2D array= (sentence_length, embedding_size)"]},{"cell_type":"code","metadata":{"id":"55inyCnJyo_M","colab_type":"code","colab":{}},"source":["embedding_dimensions = 16"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XdLQjI9vw3cw","colab_type":"text"},"source":["# get data"]},{"cell_type":"code","metadata":{"id":"Q-GfPdVrw5PV","colab_type":"code","colab":{}},"source":["!wget --no-check-certificate \\\n","https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sarcasm.json \\\n","-O /tmp/sarcasm.json"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6baq266jyxVL","colab_type":"text"},"source":["# split dataset into training & testing "]},{"cell_type":"code","metadata":{"id":"kzA2DH2yzGsR","colab_type":"code","colab":{}},"source":["with open('/tmp/sarcasm.json') as csv:\n","  # parse json object into a list\n","  datastore = json.load(csv)\n","\n","# define default data x & y lists\n","sentences = []\n","labels = []\n","\n","# iterate over datastore and append to respective lists \n","for item in datastore:\n","  sentences.append(item['headline'])\n","  labels.append(item['is_sarcastic'])\n","\n","# [:train_size] = 0 up to train_size (not including train_size value)\n","train_sentences = sentences[:train_size]\n","train_labels = labels[:train_size]\n","\n","# [train_size:] = train_size value up to end\n","test_sentences = sentences[train_size:]\n","test_labels = labels[train_size:]\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JgleAAVB0fwk","colab_type":"text"},"source":["# preprocess\n","\n","**tokenize sentences**\n","\n","tokenize means to split corpus dataset into encoded words (words in numeric representation)\n"]},{"cell_type":"code","metadata":{"id":"e8etJ16Q0nfi","colab_type":"code","colab":{}},"source":["# instantiate tokenizer to generate word index dictionary\n","  # num_words= max num_words tracked by frequency in corpus\n","  # oov_token= token substitute for out_of_vocabulary words\n","tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_token)\n","\n","# .fit_on_texts() to tokenize sentences \n","tokenizer.fit_on_texts(train_sentences)\n","\n","# get word_index dictionary= word:index\n","word_index = tokenizer.word_index\n","# print('word_index: \\n{}'.format(word_index))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bxV5xTWR1MeS","colab_type":"code","colab":{}},"source":["# texts_to_sequences() transforms list of sentences into lists of numeric representation\n","  # uses training word_index\n","sequences = tokenizer.texts_to_sequences(train_sentences)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CKqpKlVR2fYl","colab_type":"code","colab":{}},"source":["# pad_sequences() transforms sentence/sequence into a uniform input_shape \n","  # padding= 'post' because default padding adds 0's to beginning \n","  # maxlen= max length of sequence\n","train_padded = pad_sequences(sequences, maxlen=max_length, padding=pad_type, truncating=trunc_type)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2EXMZ6Pj2oRw","colab_type":"code","colab":{}},"source":["# tokenize & pad test sequences\n","# word_index is derived from training set, testing will probably generate more <OOV>\n","test_sequences = tokenizer.texts_to_sequences(test_sentences)\n","test_padded = pad_sequences(test_sequences)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uYHcwoOc2_qN","colab_type":"text"},"source":["convert into numpy arrays for model processing"]},{"cell_type":"code","metadata":{"id":"dAQ0M9bs3Szo","colab_type":"code","colab":{}},"source":["train_padded = np.array(train_padded)\n","train_labels = np.array(train_labels)\n","\n","test_padded = np.array(test_padded)\n","test_labels = np.array(test_labels)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"llMHXzh33m5w","colab_type":"text"},"source":["# define the model\n","\n","**embedding process**\n","\n","words are mapped in higher dimensional space, and semantics of the words are then learned when those words are labeled with similar meaning. \n","\n","*movie review examples:*\n","- movie reviews with positive sentiment had the dimensionality of their words ended up 'pointing' in a particular direction\n","\n","- movie reviews with negative sentiment 'pointed' in a different direction\n","\n","---\n","\n","after model training, words in future sentences could have their direction established as positive or negative (inferred sentiment)"]},{"cell_type":"code","metadata":{"id":"7yZq0H0U3yG-","colab_type":"code","colab":{}},"source":["model = keras.Sequential([\n","  # input_layer\n","  # over time, words cluster together due to the training labels (word meaning)\n","    # embedding= words found together are given similar vectors (shape & direction)\n","  # embedding output_shape=(sentence_length, embedding_size)\n","    # embedding_dimension=num_neurons                          \n","  keras.layers.Embedding(vocab_size, embedding_dimensions, input_length=max_length),\n","  # 128 5x5 filters/neurons that detect shared patterns\n","  # relu= return x if x > 0, else return 0\n","  keras.layers.Conv1D(filters=128, kernel_size=5, activation='relu'),\n","  # flatten layer that takes max values in filter and compresses, commonly used for nlp\n","  keras.layers.GlobalMaxPool1D(),\n","  # fully-connected dense layers that map inputs to outputs\n","  keras.layers.Dense(units=24, activation='relu'),\n","  # binary classification output layer\n","  # sigmoid= return 0 or 1, whichever has greater probability\n","  keras.layers.Dense(units=1, activation='sigmoid')\n","])\n","\n","model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z5e3Nr_p5uD8","colab_type":"text"},"source":["# compile the model \n","\n","build the model by compiling it with a loss, optimizer, and objective metric\n","- loss= prediction accuracy\n","- the optimizer uses the loss to adjust and imporove prediction performance\n","- metric= target"]},{"cell_type":"code","metadata":{"id":"9adrRLxb5-M8","colab_type":"code","colab":{}},"source":["# binary classification uses loss: binary_crossentropy\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JfpkVwfP6knB","colab_type":"text"},"source":["# define callbacks"]},{"cell_type":"code","metadata":{"id":"zkn7OIOU6mNw","colab_type":"code","colab":{}},"source":["# enable early_stopping to prevent overfitting\n","class myCallback(keras.callbacks.Callback):\n","  def on_epoch_end(self, epoch, logs={}):\n","    if logs.get('accuracy') >= .99:\n","      print('\\nstopping training, train accuracy > 99%')\n","      self.model.stop_training = True\n","\n","callbacks = myCallback()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IbcoQrtG6MFd","colab_type":"text"},"source":["# train the model\n","\n","fit the model to train & learn the optimal weights/relationships\n"]},{"cell_type":"code","metadata":{"id":"5WFLxA996X1P","colab_type":"code","colab":{}},"source":["%%capture\n","# assign trained model to history var for performance querying\n","history = model.fit(train_padded, train_labels, epochs=num_epochs, validation_data=(test_padded, test_labels), callbacks=[callbacks], verbose=1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lOcZyXBn67dm","colab_type":"text"},"source":["# visualize performance "]},{"cell_type":"code","metadata":{"id":"2hrsKqXh7H-I","colab_type":"code","colab":{}},"source":["plt.figure(figsize=(10,6))\n","plot_graphs(history, 'accuracy')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5v1NY6G97U_S","colab_type":"text"},"source":["# clean up\n","\n","terminate memory kernel to free up resources"]},{"cell_type":"code","metadata":{"id":"64n8wPjg7vbe","colab_type":"code","colab":{}},"source":["import os, signal\n","\n","os.kill(os.getpid(), signal.SIGKILL)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RA9lnQHP-cb8","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}